# üõ∞Ô∏è Roland-Infinity / Daowa-Maad: Attention ResU-Net for Semantic Segmentation

> *"A biologically selective AI commanded by the Infinity."*

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Stable-brightgreen)

## üìñ Descripci√≥n
**Roland-Infinity** es un modelo de segmentaci√≥n sem√°ntica de alto rendimiento dise√±ado para distinguir mascotas (perros y gatos) de fondos complejos con una precisi√≥n al **90%**.

A diferencia de las U-Nets tradicionales, este modelo implementa **Attention Gates** personalizadas que le permiten aprender caracter√≠sticas sem√°nticas robustas. Esto le otorga la capacidad √∫nica de ignorar oclusiones (rejas), objetos extra√±os (ropa) y representaciones no biol√≥gicas (dibujos/emojis), enfoc√°ndose puramente en las caracter√≠sticas biol√≥gicas del animal.

## üß† Arquitectura: Daowa-Maad
El modelo utiliza una arquitectura h√≠brida construida desde cero:

1.  **Encoder (Bajada):** Bloques residuales estilo ResNet para una extracci√≥n profunda de caracter√≠sticas.
2.  **Attention Gates:**
    * En lugar de pasar toda la informaci√≥n del Encoder al Decoder a trav√©s de las *skip connections* (como en una U-Net est√°ndar), implementamos mecanismos de atenci√≥n.
    * Estos act√∫an como filtros que suprimen las regiones irrelevantes de la imagen (fondo, ropa, ruido) y resaltan las caracter√≠sticas salientes (ojos, orejas, textura de pelo) antes de la fusi√≥n.
3.  **Decoder (Subida):** Recuperaci√≥n de la resoluci√≥n espacial mediante upsampling bilineal y convoluciones refinadas.

### üìâ M√©tricas de Entrenamiento
* **Loss Function:** Estrategia "Burn-in" (Cross Entropy inicial -> Generalized Dice Loss).
* **Optimizador:** Adam.
* **Precisi√≥n en Test (Dev):** **90.34%** (Datos / im√°genes que nunca ha visto).
* **Comportamiento:** Alta generalizaci√≥n y resistencia al overfitting.

## üöÄ Resultados

El modelo demuestra una robustez inusual en escenarios dif√≠ciles:

| Escenario | Resultado | An√°lisis |
| :--- | :--- | :--- |
| **Oclusi√≥n (Rejas)** | ‚úÖ **√âxito** | El modelo ignora los barrotes y segmenta al perro detr√°s de ellos. |
| **Out-of-Distribution (Ropa)** | ‚úÖ **√âxito** | Distingue la textura del gato vs. la textura de la tela (trajes/corbatas), recortando solo al animal. |
| **Falsos Positivos (Emojis)** | ‚úÖ **√âxito** | Discrimina entre un gato real y ediciones digitales (manos de emoji/stickers). |

## üõ†Ô∏è Instalaci√≥n y Uso

1. **Clonar el repositorio:**
   ```bash
   git clone [https://github.com/DiegoXAI-Shape/Mendicant_bias.git](https://github.com/DiegoXAI-Shape/Mendicant_bias.git)
   cd Mendicant_bias

2. **Instalar las dependencias:**
   ```bash
   pip install -r requeriments.txt
   
3. **Predecir:**
  ```
  import torch
  from model import Daowa_maad # Aseg√∫rate de importar tu clase

  # Cargar el modelo
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  model = Daowa_maad(num_clases=3).to(device)
  model.load_state_dict(torch.load("Roland_Epoch20.pth", map_location=device))
  model.eval()
 ```

-----------------------------------------------------------------------------------------------------------------------------------------------------------
# Mendicant Bias: Clasificador de Gatos vs Perros (From Kaggle) üêæ

> El sistema de visi√≥n aritifical dise√±ado y siendo todav√≠a trabajado para superar los sesgos de textura, contexto y brillo, para evitar que la red neuronal convolucional aprenda "atajos" y sea flojo al predecir diciendo: "Hay jaula, entonces es gato", lo cual es una premisa falsa para la clasificaci√≥n de perros y gatos.

# Retos
El principal reto que afront√© con este proyecto fue la ineficiencia de mis primeras arquitecturas caseras de forma secuencial la cual, no obtuvo nada de buenas m√©tricas,

Otro gran reto que afront√© fueron los sesgos y que mi modelo sea flojo al predecir en base a las caracter√≠sticas de las im√°genes, sobre todo el sesgo de textura y el sesgo de brillo.

**Restricci√≥n t√©cnica:** no usar modelos pre-entrenados, para ir conociendo m√°s a fondo las arquitecturas modernas como ResNet en base a su paper: https://arxiv.org/pdf/1512.03385

## Metodolog√≠a e Ingenier√≠a

### 1. Diagn√≥stico de Sesgos (XAI)
Utilic√© **Grad-CAM (Gradient-weighted Class Activation Mapping)** implementado manualmente con *hooks* de PyTorch para visualizar qu√© estaba "mirando" el modelo.
* **Hallazgo:** El modelo inicial ten√≠a un fuerte **Sesgo de Contexto**. Clasificaba "Gato" al detectar barrotes verticales (jaulas) y "Perro" al detectar texturas de suelo, ignorando al animal.

### 2. Limpieza y Preprocesamiento
* Implementaci√≥n de scripts de **Bash/Python** para filtrar im√°genes corruptas.
* **Data Augmentation** estrat√©gico (Rotaci√≥n, Random Invert, Color Jitter) para obligar al modelo a aprender formas y no solo colores/texturas.

### 3. Arquitectura: "Mendicant Bias v3"
Dise√±√© e implement√© una variante de **ResNet-18 desde cero** en PyTorch:
* **Stem Agresivo:** Convoluci√≥n 7x7 inicial para reducci√≥n espacial r√°pida.
* **Bloques Residuales Custom:** Implementaci√≥n manual de *Skip Connections* para evitar el desvanecimiento del gradiente.
* **Regularizaci√≥n:** Uso intensivo de `BatchNormalization`, `Dropout2d` (espacial) y `Weight Decay` para penalizar la memorizaci√≥n.

## üìà Resultados

| M√©trica | Modelo v1 (CNN Simple) | Mendicant Bias v3 (ResNet Custom) |
| :--- | :--- | :--- |
| **Precisi√≥n (Val)** | 78.3% | **96.45%** |
| **Loss** | 0.46 | **0.11** |
| **Generalizaci√≥n** | Pobre (Sesgo de textura) | **Robusta** (Ignora fondos) |

### üñºÔ∏è Evidencia Visual (Grad-CAM)
*(Aqu√≠ puedes poner tus im√°genes del antes y despu√©s)*
* **Antes:** El heatmap se encend√≠a en la jaula.
* **Despu√©s:** El heatmap se enfoca exclusivamente en la cara y orejas del animal, ignorando el entorno.

## üíª Tecnolog√≠as
* **PyTorch** (Entrenamiento, Arquitectura, Hooks)
* **OpenCV** (Preprocesamiento y visualizaci√≥n)
* **Pandas/NumPy** (An√°lisis de datos)
* **CUDA** (Entrenamiento en GPU)

---
*Proyecto desarrollado por Diego Asael Hern√°ndez Cardona.*
